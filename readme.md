# Ticket Classification MLOps

# Industrialisation d'un Pipeline NLP de Classification de Tickets Support avec MLOps

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Supported-326CE5.svg)](https://kubernetes.io/)
[![MLOps](https://img.shields.io/badge/MLOps-Enabled-green.svg)](https://ml-ops.org/)

---

## Contexte du Projet

Ce projet a √©t√© r√©alis√© dans le cadre d'une mission en entreprise IT disposant d'un historique d'emails de support client.

Chaque ticket contient :
- **Champs textuels** : `subject`, `body`, `answer`
- **M√©tadonn√©es m√©tier** : priorit√©, type, queue, langue, etc.

### Objectif

Industrialiser un pipeline batch NLP permettant de :

1. Traiter et comprendre le contenu des emails support
2. G√©n√©rer des repr√©sentations s√©mantiques (embeddings) avec un mod√®le Hugging Face
3. Entra√Æner un mod√®le de classification supervis√©e pour pr√©dire le type de ticket
4. Stocker les embeddings dans une base vectorielle ChromaDB
5. Surveiller la qualit√© du mod√®le et la d√©rive des donn√©es avec Evidently AI
6. Superviser l'infrastructure avec Prometheus et Grafana

> **Note** : L'ensemble du projet est ex√©cut√© dans un environnement containeris√© (Docker & Kubernetes) **sans exposition d'API**.

---

## Structure du Projet


```
‚îú‚îÄ‚îÄ üìÅ .github
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ workflows
‚îÇ       ‚îî‚îÄ‚îÄ ‚öôÔ∏è ml-pipeline.yml
‚îú‚îÄ‚îÄ üìÅ Nootbooks
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ eda.ipynb
‚îú‚îÄ‚îÄ üìÅ data
‚îú‚îÄ‚îÄ üìÅ k8s
‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è chromadb.yaml
‚îÇ   ‚îî‚îÄ‚îÄ ‚öôÔ∏è ml.yaml
‚îú‚îÄ‚îÄ üìÅ models
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ artifacts
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ trained
‚îú‚îÄ‚îÄ üìÅ monitoring
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ grafana
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ dashboards
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ prometheus
‚îú‚îÄ‚îÄ üìÅ src
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç cleaning.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ dataset.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç encoding.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç load_data.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ features
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç embedding_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç evaluate.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç split.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç train.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ monitoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç drift_detection.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç evendently_report.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ vectors_store
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç chromadb_client.py
‚îÇ   ‚îî‚îÄ‚îÄ üêç __init__.py
‚îú‚îÄ‚îÄ ‚öôÔ∏è .dockerignore
‚îú‚îÄ‚îÄ ‚öôÔ∏è .env.example
‚îú‚îÄ‚îÄ ‚öôÔ∏è .gitignore
‚îú‚îÄ‚îÄ üê≥ Dockerfile
‚îú‚îÄ‚îÄ ‚öôÔ∏è docker-compose.yml
‚îú‚îÄ‚îÄ ‚öôÔ∏è prometheus.yml
‚îú‚îÄ‚îÄ üìù readme.md
‚îî‚îÄ‚îÄ üìÑ requirements.txt
```
---

## √âtapes du Pipeline

### 1. Analyse Exploratoire & Pr√©paration NLP

- Analyse des types de tickets, longueur des emails
- Fusion des champs textuels (`subject + body`)
- Nettoyage NLP :
  - Conversion en minuscules
  - Suppression de la ponctuation
  - Tokenisation
  - Suppression des stopwords selon la langue

### 2. G√©n√©ration d'Embeddings

- S√©lection d'un mod√®le pr√©-entra√Æn√© Hugging Face (`all-MiniLM-L6-v2`)
- Encodage des textes nettoy√©s en vecteurs
- Normalisation des vecteurs
- Stockage dans ChromaDB

### 3. Entra√Ænement du Mod√®le de Classification

- S√©paration train/test
- Entra√Ænement avec scikit-learn (ex: RandomForest ou Logistic Regression)
- √âvaluation : pr√©cision, recall, F1-score

### 4. Monitoring ML avec Evidently AI

- D√©finition d'un jeu de r√©f√©rence (baseline)
- Suivi de **data drift** et **prediction drift**
- G√©n√©ration de rapports HTML interactifs

### 5. Conteneurisation et Orchestration

- Dockerisation du pipeline NLP & ML
- D√©ploiement batch sur Kubernetes (Minikube)
- CI/CD avec GitHub Actions (lint + build Docker)

### 6. Monitoring Infrastructure avec Prometheus & Grafana

- **Node Exporter** : m√©triques CPU/RAM/disque
- **cAdvisor** : consommation des containers Docker
- Dashboards Grafana configur√©s pour visualisation

---

## üõ†Ô∏è D√©pendances Principales

- Python >= 3.10
- pandas, numpy, scikit-learn, nltk
- langchain_community.embeddings
- ChromaDB
- Docker & Kubernetes
- Prometheus & Grafana
- Evidently AI

---

## Instructions pour Ex√©cuter le Pipeline

### 1. Installer l'Environnement

```bash
python -m venv env
source env/bin/activate  # Sur Windows: env\Scripts\activate
pip install -r requirements.txt
```

### 2. Pr√©traitement des Donn√©es

```python
from src.data.load_data import load_data
from src.data.cleaning import cleaning
from src.data.encoding import encoding

df = load_data()
df_clean = cleaning(df)
df_encoded = encoding(df_clean)
```

### 3. G√©n√©ration et Stockage des Embeddings

```python
from src.features.embedding_generator import generate_embeddings

generate_embeddings(df_encoded)
```

### 4. Ex√©cution du Mod√®le de Classification

```python
from src.models.classifier import train_model, evaluate_model

model = train_model(X_train, y_train)
metrics = evaluate_model(model, X_test, y_test)
```

### 5. Monitoring ML

```python
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset, ClassificationPreset

# G√©n√©ration de rapports Evidently AI pour data/prediction drift
report = Report(metrics=[DataDriftPreset(), ClassificationPreset()])
report.run(reference_data=reference_df, current_data=current_df)
report.save_html("drift_report.html")
```

### 6. Ex√©cution Containeris√©e

```bash
# Build Docker image
docker build -t ticket-nlp-pipeline ./docker

# D√©ploiement sur Kubernetes
kubectl apply -f k8s/
```

### 7. Monitoring Infrastructure

```bash
cd monitoring
docker-compose up -d
```

Acc√®s aux interfaces :
- **Prometheus** : http://localhost:9090
- **Grafana** : http://localhost:3000 (admin/admin)

---

## Livrables

- ‚úÖ Scripts de preprocessing NLP
- ‚úÖ Embeddings stock√©s dans ChromaDB
- ‚úÖ Mod√®le de classification entra√Æn√©
- ‚úÖ Rapports Evidently AI
- ‚úÖ Images Docker & manifests Kubernetes
- ‚úÖ Rapport technique final

---

## Crit√®res de Performance

| Crit√®re | Description |
|---------|-------------|
| **Qualit√© NLP** | Nettoyage efficace des textes, tokenisation adapt√©e |
| **Embeddings** | Coh√©rence des vecteurs et indexation ChromaDB optimale |
| **Classification** | Pr√©cision > 85%, F1-score √©quilibr√© |
| **Monitoring ML** | D√©tection proactive de drift avec Evidently AI |
| **Infrastructure** | Dashboards Prometheus/Grafana op√©rationnels |
| **Reproductibilit√©** | Pipeline compl√®tement automatis√© via Docker/Kubernetes |

---

## Remarques

- Le pipeline est con√ßu pour √™tre **batch**, non expos√© en API
- Toutes les √©tapes sont supervis√©es via MLOps pour garantir stabilit√© et maintenance continue
- L'orchestration Kubernetes permet une scalabilit√© horizontale
- Les m√©triques de monitoring permettent une d√©tection pr√©coce des anomalies

---


